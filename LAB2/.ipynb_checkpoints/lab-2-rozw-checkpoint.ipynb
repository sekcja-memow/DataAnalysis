{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zajecia2_rozw.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFHSNZ-iTU2p",
        "colab_type": "text"
      },
      "source": [
        "# Laboratorium 2: ewaluacja metod uczenia maszynowego\n",
        "\n",
        "W ramach laboratorium omówiona zostanie ewaluacja metod uczenia maszynowego ze szczególnym uwzględnieniem problemu regresji."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doIptr5uTULW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "boston = datasets.load_boston()\n",
        "print(boston.DESCR)\n",
        "\n",
        "print(\"boston (shape): \", boston.data.shape)\n",
        "\n",
        "print(boston.target)\n",
        "\n",
        "# Wycinamy kawałek danych do testów:\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    boston.data, boston.target, test_size=0.2, random_state=421, shuffle=True)\n",
        "\n",
        "print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p80GeP8VHz4",
        "colab_type": "text"
      },
      "source": [
        "## Regresja liniowa\n",
        "\n",
        "Przejrzyj poniższy kod.\n",
        "Policz współczynniki $R^2$ na zbiorze testowym i treningowym.\n",
        "Jak się je interpretuje? Który powinien być większy?\n",
        "Policz też błędy średniokwadratowe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YtjkVi6VKcp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "lr = linear_model.LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "def evaluate_reg(reg):\n",
        "  pred_test = reg.predict(X_test)\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.scatter(y_test, pred_test, edgecolors=(0, 0, 0))\n",
        "  ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
        "  ax.set_xlabel('Measured')\n",
        "  ax.set_ylabel('Predicted')\n",
        "  plt.show()\n",
        "\n",
        "  ## solution \n",
        "\n",
        "  print(\"MSE train: \", mean_squared_error(y_train, reg.predict(X_train)))\n",
        "  print(\"MSE test:  \", mean_squared_error(y_test, reg.predict(X_test)))\n",
        "\n",
        "evaluate_reg(lr)\n",
        "\n",
        "## solution\n",
        "\n",
        "print(\"R2 train: \", lr.score(X_train, y_train))\n",
        "print(\"R2 test:  \", lr.score(X_test, y_test))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI-787LaonkF",
        "colab_type": "text"
      },
      "source": [
        "## Ridge regression\n",
        "\n",
        "Przeprowadź analogiczną procedurę jak w poprzednim punkcie, ale z wykorzystaniem *Ridge regression*.\n",
        "Sprawdź, które współczynniki regresji są równe zero. Co to oznacza? Jakim parametrom w danych odpowiadają te cechy?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL73Ozgvo-Ln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "reg_ridge = linear_model.Ridge(alpha=1)\n",
        "reg_lasso = linear_model.Lasso(alpha=0.5)\n",
        "\n",
        "reg = reg_lasso\n",
        "\n",
        "reg.fit(X_train, y_train)\n",
        "evaluate_reg(reg)\n",
        "print(\"Params: \", reg.coef_)\n",
        "print(\"Intercept: \", reg.intercept_)\n",
        "\n",
        "## solution \n",
        "print(\"R2 train: \", reg.score(X_train, y_train))\n",
        "print(\"R2 test:  \", reg.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SDSfODcY3yz",
        "colab_type": "text"
      },
      "source": [
        "## Drzewa regresji\n",
        "\n",
        "Dopasuj kilkukrotnie model drzewa regresji. W jakim zakresie zmienia się błąd na zbiorze treningowym?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8YC16fKY3A-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import tree\n",
        "\n",
        "reg = tree.DecisionTreeRegressor()\n",
        "\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "evaluate_reg(reg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tk1PiaRI5MBx",
        "colab_type": "text"
      },
      "source": [
        "## Walidacja krzyżowa\n",
        "\n",
        "Zaobserwuj stabilność średniej z MSE przy wykorzystaniu walidacji krzyżowej.\n",
        "Dopisz sprawdzanie błędów poszczególnych metod regresji na zbiorze testowym (normalnie tego się **nie** robi -- to jest tylko dla celów poglądowych). Zastanów się skąd może brać się różnica.\n",
        "\n",
        "Porównaj wyniki dla drzew regresji i metody Lasso z wcześniejszego zadania."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Te2IOEH5OOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "errors_resub = []\n",
        "errors_valid = []\n",
        "errors_test = []\n",
        "for train_idx, valid_idx in kf.split(X_train):\n",
        "  X_t_f, X_v_f = X_train[train_idx], X_train[valid_idx]\n",
        "  y_t_f, y_v_f = y_train[train_idx], y_train[valid_idx]\n",
        "\n",
        "  #reg = tree.DecisionTreeRegressor()\n",
        "  reg = linear_model.Lasso(alpha=0.5)\n",
        "  reg.fit(X_t_f, y_t_f)\n",
        "  errors_resub.append(mean_squared_error(y_t_f, reg.predict(X_t_f)))\n",
        "  errors_valid.append(mean_squared_error(y_v_f, reg.predict(X_v_f)))\n",
        "  errors_test.append(mean_squared_error(y_test, reg.predict(X_test)))\n",
        "\n",
        "\n",
        "print(sum(errors_resub)/kf.n_splits)\n",
        "print(sum(errors_valid)/kf.n_splits)\n",
        "print(sum(errors_test)/kf.n_splits)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p21tVotgvm6",
        "colab_type": "text"
      },
      "source": [
        "## Optymalizacja parametrów\n",
        "\n",
        "Z użyciem walidacji krzyżowej.\n",
        "\n",
        "Znajdź optymalną wartość parametru `alpha` dla metody Lasso.\n",
        "\n",
        "Następnie znajdź optymalne parametry dla metody `DecisionTreeRegressor` (na przykład `max_depth`, `min_samples_leaf`). Spróbuj zmodyfikować także inne parametry i sprawdź rezultaty.\n",
        "\n",
        "Napisz własną funkcję oceniającą model regresji tak, aby premiowała małe drzewa. Ile minimum węzłów w drzewie potrzebujesz aby MSE na zbiorze testowym było mniejsze niż 15?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP123T70g2Q_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {'alpha': [0.1, 0.5 , 1.0, 5.0, 10.0]}\n",
        "lasso_reg = linear_model.Lasso()\n",
        "gcv_reg = GridSearchCV(lasso_reg, parameters, scoring='neg_mean_squared_error')\n",
        "gcv_reg.fit(X_train, y_train)\n",
        "print(gcv_reg.best_params_)\n",
        "\n",
        "print(\"MSE train: \", mean_squared_error(y_train, gcv_reg.predict(X_train)))\n",
        "print(\"MSE test:  \", mean_squared_error(y_test, gcv_reg.predict(X_test)))\n",
        "\n",
        "grid_tree = {'max_depth': [1, 2, 3, 4, None], 'min_samples_leaf': [1, 2, 4, 8]}\n",
        "tree_reg = tree.DecisionTreeRegressor()\n",
        "gcv_reg = GridSearchCV(tree_reg, grid_tree, scoring='neg_mean_squared_error')\n",
        "gcv_reg.fit(X_train, y_train)\n",
        "print(gcv_reg.best_params_)\n",
        "\n",
        "tree.plot_tree(gcv_reg.best_estimator_)\n",
        "\n",
        "print(\"MSE train: \", mean_squared_error(y_train, gcv_reg.predict(X_train)))\n",
        "print(\"MSE test:  \", mean_squared_error(y_test, gcv_reg.predict(X_test)))\n",
        "print(\"Nodes: \", gcv_reg.best_estimator_.tree_.node_count)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}